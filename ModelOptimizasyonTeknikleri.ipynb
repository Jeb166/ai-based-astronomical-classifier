{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "70d97216",
   "metadata": {},
   "source": [
    "# Model Optimizasyon Teknikleri\n",
    "\n",
    "Bu notebook, yıldız modeli için kullanabileceğiniz model optimizasyon tekniklerini detaylı olarak açıklar. İşte ileri düzey model optimizasyon teknikleri hakkında detaylı bilgi:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d7b51ee",
   "metadata": {},
   "source": [
    "## 1. Daha Kapsamlı Hiperparametre Araması\n",
    "\n",
    "Şu anda `optimize_star_model.py` dosyasında rastgele 10 kombinasyon denenmiş, ancak daha etkin arama yöntemleri kullanabiliriz:\n",
    "\n",
    "### 1.1 Bayesian Optimizasyon\n",
    "\n",
    "Bayesian optimizasyon, bir işlevi doğrudan değerlendirmeden değerlerini tahmin etmeye çalışan olasılıksal bir model kurar ve bir kazanım fonksiyonunu eniyilemeye çalışır.\n",
    "\n",
    "**Avantajları:**\n",
    "- Verimlilik: Rastgele aramadan daha az deneme ile daha iyi sonuçlar\n",
    "- Akıllı arama: Önceki denemelerden öğrenir ve umut vadeden bölgeleri keşfeder\n",
    "- Arama verimliliği: Rastgele arama ve grid search'e göre denemeler arasında daha iyi bir öğrenme eğrisi gösterir\n",
    "\n",
    "**Nasıl uygulanır:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb9ba5ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bayesian Optimizasyon Örneği\n",
    "from skopt import BayesSearchCV\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "# Keras modelini sarma fonksiyonu\n",
    "def create_model_wrapper(neurons1=256, neurons2=128, neurons3=64, dropout1=0.4, \n",
    "                         dropout2=0.4, dropout3=0.3, learning_rate=0.001):\n",
    "    def _create_model():\n",
    "        model = build_star_model(\n",
    "            n_features, n_classes, \n",
    "            neurons1=neurons1, neurons2=neurons2, neurons3=neurons3,\n",
    "            dropout1=dropout1, dropout2=dropout2, dropout3=dropout3,\n",
    "            learning_rate=learning_rate\n",
    "        )\n",
    "        return model\n",
    "    return _create_model\n",
    "\n",
    "# KerasClassifier oluştur\n",
    "model = KerasClassifier(build_fn=create_model_wrapper())\n",
    "\n",
    "# Arama alanını tanımla\n",
    "param_space = {\n",
    "    'build_fn__neurons1': (128, 512),        # Sürekli aralık\n",
    "    'build_fn__neurons2': (64, 256),         # Sürekli aralık\n",
    "    'build_fn__dropout1': (0.2, 0.5),        # Sürekli aralık\n",
    "    'build_fn__learning_rate': (1e-4, 1e-2), # Logaritmik ölçek\n",
    "    'batch_size': [32, 64, 128, 256],        # Kategorik\n",
    "    'epochs': [15, 20, 25]                   # Kategorik\n",
    "}\n",
    "\n",
    "# Bayesian aramasını oluştur\n",
    "bayes_search = BayesSearchCV(\n",
    "    model, param_space, n_iter=20,          # Sadece 20 kombinasyon dene\n",
    "    cv=3, scoring='accuracy',\n",
    "    verbose=1, n_jobs=1, random_state=42\n",
    ")\n",
    "\n",
    "# Aramayı gerçekleştir\n",
    "bayes_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2b1e70d",
   "metadata": {},
   "source": [
    "### 1.2 Grid Search (Izgara Araması)\n",
    "\n",
    "Grid search, hiperparametre uzayında belirtilen tüm olası kombinasyonları sistematik olarak değerlendirir.\n",
    "\n",
    "**Avantajları:**\n",
    "- Kapsamlı: Belirtilen aralıktaki tüm kombinasyonları dener\n",
    "- Basit: Anlaşılması ve uygulaması kolaydır\n",
    "- Paralel Çalışma: Paralel işleme çok uygundur\n",
    "\n",
    "**Dezavantajları:**\n",
    "- Boyut Laneti: Hiperparametre sayısı arttıkça kombinasyon sayısı üssel olarak artar\n",
    "- Verimsizlik: Kötü kombinasyonlar için bile zaman harcar\n",
    "\n",
    "**Nasıl uygulanır:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a61755a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid Search Örneği\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Kısıtlı parametre alanı (hesaplama süresi için)\n",
    "param_grid = {\n",
    "    'build_fn__neurons1': [128, 256, 512],\n",
    "    'build_fn__neurons2': [64, 128, 256],\n",
    "    'build_fn__dropout1': [0.3, 0.4, 0.5],\n",
    "    'build_fn__learning_rate': [0.0001, 0.001, 0.01],\n",
    "    'batch_size': [64, 128],\n",
    "    'epochs': [15, 20]\n",
    "}\n",
    "\n",
    "# Grid search'ü oluştur\n",
    "grid_search = GridSearchCV(\n",
    "    model, param_grid, cv=3, scoring='accuracy',\n",
    "    verbose=1, n_jobs=1\n",
    ")\n",
    "\n",
    "# Bazen grid search çok fazla hesaplama gücü gerektirir\n",
    "# Örneğin burada: 3x3x3x3x2x2 = 324 kombinasyon\n",
    "# Bu nedenle genellikle hiperparametreleri gruplar halinde optimize ederiz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "781163fa",
   "metadata": {},
   "source": [
    "## 2. Daha Hafif Modeller\n",
    "\n",
    "### 2.1 DepthwiseSeparableConv \n",
    "\n",
    "DepthwiseSeparableConv (Derinliğe göre ayrılabilir evrişim), standart evrişimsel katmanların daha verimli bir versiyonudur. İki adımda çalışır: derinlemesine evrişim ve noktasal evrişim. Bu ayrım, parametre sayısını ve hesaplama yükünü önemli ölçüde azaltır. \n",
    "\n",
    "Bu kavram, yoğun (dense) sinir ağları için de uygulanabilir:\n",
    "\n",
    "**SeparableFC (Ayrılabilir Tam Bağlantılı) Katmanlar:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d5fa08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SeparableFC katmanı uygulaması\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Layer\n",
    "\n",
    "class SeparableFC(Layer):\n",
    "    \"\"\"Ayırmalabilir tam bağlantılı katman (Dense katmanının hafif versiyonu)\"\"\"\n",
    "    \n",
    "    def __init__(self, units, rank=8, activation=None, **kwargs):\n",
    "        super(SeparableFC, self).__init__(**kwargs)\n",
    "        self.units = units\n",
    "        self.rank = rank  # Ayırma boyutu\n",
    "        self.activation = tf.keras.activations.get(activation)\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        input_dim = int(input_shape[-1])\n",
    "        \n",
    "        # İki küçük matris oluşturarak parametre sayısını azalt\n",
    "        # Standart FC: input_dim * units parametre\n",
    "        # Ayrılabilir FC: input_dim * rank + rank * units parametre\n",
    "        \n",
    "        self.w1 = self.add_weight(\n",
    "            shape=(input_dim, self.rank),\n",
    "            initializer='glorot_uniform',\n",
    "            name='w1'\n",
    "        )\n",
    "        self.w2 = self.add_weight(\n",
    "            shape=(self.rank, self.units),\n",
    "            initializer='glorot_uniform',\n",
    "            name='w2'\n",
    "        )\n",
    "        self.bias = self.add_weight(\n",
    "            shape=(self.units,),\n",
    "            initializer='zeros',\n",
    "            name='bias'\n",
    "        )\n",
    "        self.built = True\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        # İki adımda hesapla\n",
    "        x = tf.matmul(inputs, self.w1)  # (batch, input_dim) x (input_dim, rank)\n",
    "        x = tf.matmul(x, self.w2)       # (batch, rank) x (rank, units)\n",
    "        x = tf.nn.bias_add(x, self.bias)\n",
    "        \n",
    "        if self.activation is not None:\n",
    "            x = self.activation(x)\n",
    "        return x\n",
    "    \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0], self.units)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42adab62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hafif model yapısında bu katmanı kullanma örneği\n",
    "def build_lightweight_separable_model(input_dim, n_classes, rank=16):\n",
    "    from tensorflow.keras.models import Sequential\n",
    "    from tensorflow.keras.layers import BatchNormalization, Dropout, Activation\n",
    "    \n",
    "    model = Sequential([\n",
    "        SeparableFC(256, rank=rank, input_shape=(input_dim,)),\n",
    "        Activation('relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.3),\n",
    "        \n",
    "        SeparableFC(128, rank=rank),\n",
    "        Activation('relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.3),\n",
    "        \n",
    "        SeparableFC(n_classes, rank=rank),\n",
    "        Activation('softmax')\n",
    "    ])\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['categorical_accuracy']\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f98e932",
   "metadata": {},
   "source": [
    "### 2.2 Parametresi Azaltılmış Mimari: Ağaç Yapılı Sinir Ağları\n",
    "\n",
    "Tüm nöronlar arasında tam bağlantı kurmak yerine, hiyerarşik bağlantılar kuran bir ağaç yapısı kullanılabilir. Bu yaklaşım, uzay jeometrisiyle ilgili özellikle astronomi verilerinde işe yarayabilir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a42f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ağaç yapılı mimarinin Keras ile gerçekleştirilmesi\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, concatenate, BatchNormalization, Dropout\n",
    "\n",
    "def build_tree_model(input_dim, n_classes):\n",
    "    \"\"\"\n",
    "    Ağaç yapılı sinir ağı.\n",
    "    Daha az parametre kullanır ve domain bilgisini modele dahil eder.\n",
    "    \"\"\"\n",
    "    # Girdi\n",
    "    inputs = Input(shape=(input_dim,))\n",
    "    \n",
    "    # İlk seviye: Özellik gruplarını ayır (örn. renk indeksleri, parlaklıklar, vs)\n",
    "    # Astronomik verilerde bu mantıklı çünkü farklı özellik grupları farklı bilgiler taşır\n",
    "    \n",
    "    # Renk indeksi özellikleri (u-g, g-r, r-i, i-z gibi)\n",
    "    color_feats = Dense(64, activation='relu')(inputs)\n",
    "    color_feats = BatchNormalization()(color_feats)\n",
    "    color_feats = Dropout(0.3)(color_feats)\n",
    "    \n",
    "    # Parlaklık özellikleri (u, g, r, i, z gibi)\n",
    "    magnitude_feats = Dense(64, activation='relu')(inputs)\n",
    "    magnitude_feats = BatchNormalization()(magnitude_feats)\n",
    "    magnitude_feats = Dropout(0.3)(magnitude_feats)\n",
    "    \n",
    "    # Diğer özellikler\n",
    "    other_feats = Dense(32, activation='relu')(inputs)\n",
    "    other_feats = BatchNormalization()(other_feats)\n",
    "    other_feats = Dropout(0.3)(other_feats)\n",
    "    \n",
    "    # İkinci seviye: Alt özellikleri birleştir\n",
    "    combined = concatenate([color_feats, magnitude_feats, other_feats])\n",
    "    \n",
    "    # Çıktı katmanı\n",
    "    outputs = Dense(128, activation='relu')(combined)\n",
    "    outputs = BatchNormalization()(outputs)\n",
    "    outputs = Dropout(0.3)(outputs)\n",
    "    outputs = Dense(n_classes, activation='softmax')(outputs)\n",
    "    \n",
    "    # Model oluştur\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['categorical_accuracy']\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84dc8f51",
   "metadata": {},
   "source": [
    "## 3. Erken Durdurma ve Öğrenme Oranı Stratejilerini Optimize Etme\n",
    "\n",
    "### 3.1 Gelişmiş Erken Durdurma Stratejileri\n",
    "\n",
    "Standart erken durdurma, doğrulama kaybı iyileşmeyi durduğunda eğitimi sonlandırır. Ancak daha gelişmiş stratejiler kullanabilirsiniz:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "972be313",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gelişmiş erken durdurma ve öğrenme oranı planları\n",
    "from tensorflow.keras.callbacks import Callback, LearningRateScheduler, EarlyStopping\n",
    "import numpy as np\n",
    "\n",
    "# Trendi izleyen erken durdurma\n",
    "class TrendingEarlyStopping(Callback):\n",
    "    \"\"\"Sadece tek bir plateau için değil, uzun vadeli eğilimi izleyen erken durdurma\"\"\"\n",
    "    \n",
    "    def __init__(self, monitor='val_loss', patience=5, window_size=10, min_delta=0):\n",
    "        super(TrendingEarlyStopping, self).__init__()\n",
    "        self.monitor = monitor\n",
    "        self.patience = patience\n",
    "        self.window_size = window_size\n",
    "        self.min_delta = min_delta\n",
    "        self.wait = 0\n",
    "        self.best = float('inf') if 'loss' in monitor else -float('inf')\n",
    "        self.history = []\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        logs = logs or {}\n",
    "        current = logs.get(self.monitor)\n",
    "        if current is None:\n",
    "            return\n",
    "        \n",
    "        self.history.append(current)\n",
    "        \n",
    "        if len(self.history) >= self.window_size:\n",
    "            # Son window_size değerini kullanarak eğilimi hesapla\n",
    "            recent = self.history[-self.window_size:]\n",
    "            # Doğrusal regresyon eğimi\n",
    "            x = np.arange(len(recent))\n",
    "            slope = np.polyfit(x, recent, 1)[0]\n",
    "            \n",
    "            # 'loss' için negatif eğim iyidir, diğer metrikler için pozitif\n",
    "            is_improving = slope < -self.min_delta if 'loss' in self.monitor else slope > self.min_delta\n",
    "            \n",
    "            if not is_improving:\n",
    "                self.wait += 1\n",
    "                if self.wait >= self.patience:\n",
    "                    self.model.stop_training = True\n",
    "            else:\n",
    "                self.wait = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50862231",
   "metadata": {},
   "source": [
    "### 3.2 Gelişmiş Öğrenme Oranı Planları\n",
    "\n",
    "ReduceLROnPlateau'dan daha sofistike öğrenme oranı stratejileri kullanabilirsiniz:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c6c01cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Döngüsel öğrenme oranı\n",
    "def cyclic_learning_rate(epoch, min_lr=1e-6, max_lr=1e-3, cycle_length=10):\n",
    "    \"\"\"Döngüsel öğrenme oranı planı - ısınma/soğutma döngüleri ile\"\"\"\n",
    "    # Döngü içindeki mevcut konum (0 ile 1 arasında)\n",
    "    cycle_progress = (epoch % cycle_length) / cycle_length\n",
    "    \n",
    "    # Kosinüs dalgası (0 ile 1 arasında, yarım döngü)\n",
    "    cos_wave = 0.5 * (1 + np.cos(np.pi * (cycle_progress * 2 - 1)))\n",
    "    \n",
    "    # Logaritmik ölçekte yumuşak geçiş\n",
    "    log_min, log_max = np.log10(min_lr), np.log10(max_lr)\n",
    "    log_lr = log_min + cos_wave * (log_max - log_min)\n",
    "    \n",
    "    return 10 ** log_lr\n",
    "\n",
    "# Isınma dönemi olan adımlı düşüş\n",
    "def warmup_step_decay(epoch, initial_lr=0.001, min_lr=1e-6, warmup_epochs=3, \n",
    "                    drop_epochs=[10, 15, 20], drop_factor=0.2):\n",
    "    \"\"\"Isınma dönemi ve önceden belirlenmiş dönemlerde adımlı düşüş\"\"\"\n",
    "    if epoch < warmup_epochs:\n",
    "        # Isınma dönemi: 0'dan initial_lr'ye doğrusal artış\n",
    "        return initial_lr * ((epoch + 1) / warmup_epochs)\n",
    "    \n",
    "    # Adımlı düşüş\n",
    "    lr = initial_lr\n",
    "    for e in drop_epochs:\n",
    "        if epoch >= e:\n",
    "            lr *= drop_factor\n",
    "    \n",
    "    return max(lr, min_lr)  # Minimum değerden düşük olamaz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86549743",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bu stratejileri modelde kullanma örneği\n",
    "def train_with_advanced_strategies(model, X_train, y_train, X_val, y_val, epochs=30):\n",
    "    # Öğrenme oranı planını ayarla\n",
    "    lr_scheduler = LearningRateScheduler(\n",
    "        lambda epoch: cyclic_learning_rate(epoch)\n",
    "    )\n",
    "    \n",
    "    # Gelişmiş erken durdurma\n",
    "    trend_stopping = TrendingEarlyStopping(\n",
    "        monitor='val_categorical_accuracy',\n",
    "        patience=3,\n",
    "        window_size=8,\n",
    "        min_delta=0.001\n",
    "    )\n",
    "    \n",
    "    # Model eğitimi\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_val, y_val),\n",
    "        epochs=epochs,\n",
    "        batch_size=128,\n",
    "        callbacks=[\n",
    "            lr_scheduler,\n",
    "            trend_stopping\n",
    "        ],\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "545802b3",
   "metadata": {},
   "source": [
    "## Colab Uygulaması İçin Notlar\n",
    "\n",
    "Bu optimizasyon stratejilerini Colab'de uygulamak için birkaç ipucu:\n",
    "\n",
    "1. **Google Colab TPU/GPU Kullanımı**: Colab'de hızlı eğitim için TPU/GPU kullanmayı açın\n",
    "\n",
    "2. **Eğitim Takibi**: TensorBoard ile eğitim metriklerini görselleştirin\n",
    "\n",
    "3. **Checkpoint Kaydetme**: Uzun eğitimler için ara modelleri kaydedin\n",
    "\n",
    "4. **Hyperparameter Tuning**: Colab'de parametre aramayı etkin bir şekilde paralel çalıştırmak için stratejiler\n",
    "\n",
    "Yukarıdaki teknikleri kullanarak modelinizi hem daha hızlı eğitebilir hem de daha yüksek doğruluk elde edebilirsiniz."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
